{"id": "q1", "query": "What is a large language model?", "answer": "A computational agent that assigns probabilities to sequences of words and can interact conversationally.", "gold_snippet": "Large language modelsComputational agents that can interact conversationally"}
{"id": "q2", "query": "What is BM25 used for in information retrieval?", "answer": "A sparse retrieval / ranking algorithm (BM25) used to rank documents.", "gold_snippet": "BM25"}
{"id": "q3", "query": "What is an n-gram language model?", "answer": "A model that assigns probabilities to sequences of words using the previous n-1 words.", "gold_snippet": "A language model is a machine learning model that predicts upcoming words"}
{"id": "q4", "query": "What does dense retrieval use instead of tf-idf?", "answer": "Dense retrieval uses embeddings (dense vectors) to represent queries and documents.", "gold_snippet": "Dense retrievalInstead of representing query and documents with count vectors"}
{"id": "q5", "query": "What is top-k sampling?", "answer": "Truncate the token distribution to the top-k most probable tokens and sample from them.", "gold_snippet": "Top-k sampling is a simple generalization of greedy decoding"}
{"id": "q6", "query": "What is peerplexity as an evaluation metric?", "answer": "The inverse probability of the test set normalized by the number of tokens (lower is better).", "gold_snippet": "Perplexity is the inverse probability of the test set, normalized by the number of words"}
